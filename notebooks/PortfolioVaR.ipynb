{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PortfolioVaR.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOJSZkYroQ0Lx9SDmKv7wQG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mjboothaus/rewarding-risk/blob/main/notebooks/PortfolioVaR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating Value at Risk (VaR) of a stock portfolio using Python\n",
        "\n",
        "## What is Value at risk (VaR)?\n",
        "\n",
        "Value at risk (VaR) is a statistic used to try and quantify the level of financial risk within a firm or portfolio over a specified time frame. VaR provides an estimate of the maximum loss from a given position or portfolio over a period of time, and you can calculate it across various confidence levels.\n",
        "\n",
        "Estimating the risk of a portfolio is important to long-term capital growth and risk management, particularly within larger firms or institutions. VaR is typically framed as something like this:\n",
        "\n",
        "\"We have a portfolio VaR of 250,000 USD over the next month at 95% confidence\"\n",
        "This means that, with 95% confidence, we can say that the portfolio's loss will not exceed 250,000 USD in a month\n",
        "In this post I'll walk you through the steps to calculate this metric across a portfolio of stocks.\n",
        "\n",
        "\n",
        "## How is VaR calculated?\n",
        "\n",
        "There are two main ways to calculate VaR:\n",
        "1. Using Monte Carlo simulation\n",
        "2. Using the variance-covariance method\n",
        "\n",
        "In this post, we'll focus on using method (2) (variance-covariance). In short, the variance-covariance method looks at historical price movements (standard deviation, mean price) of a given equity or portfolio of equities over a specified lookback period, and then uses probability theory to calculate the maximum loss within your specified confidence interval. You can read more detail here, but we'll calculate it step by step below using Python.\n",
        "\n",
        "Before we get started, note that the standard VaR calculation assumes the following:\n",
        "1. Normal distribution of returns - VaR assumes the returns of the portfolio are normally distributed. This is of course not realistic for most assets, but allows us to develop a baseline using a much more simplistic calculation.\n",
        "(Modifications can be made to VaR to account for different distributions, but here we'll focus on the standard VaR calculation)\n",
        "2. Standard market conditions - Like many financial instruments, VaR is best used for considering loss in standard markets, and is not well-suited for extreme/outlier events.\n",
        "\n",
        "## Steps to calculate the VaR of a portfolio\n",
        "\n",
        "In order to calculate the VaR of a portfolio, you can follow the steps below:\n",
        "1. Calculate periodic returns of the stocks in the portfolio\n",
        "2. Create a covariance matrix based on the returns\n",
        "3. Calculate the portfolio mean and standard deviation\n",
        "(weighted based on investment levels of each stock in portfolio)\n",
        "4. Calculate the inverse of the normal cumulative distribution (PPF) with a specified confidence interval, standard deviation, and mean\n",
        "5. Estimate the value at risk (VaR) for the portfolio by subtracting the initial investment from the calculation in step (4)\n",
        "\n",
        "### Reference\n",
        "\n",
        "https://www.interviewqs.com/blog/value-at-risk"
      ],
      "metadata": {
        "id": "yJrVaoVAMd9h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0) Setup"
      ],
      "metadata": {
        "id": "z4qRPACCNYuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade pandas-datareader   # need to update otherwise it fails"
      ],
      "metadata": {
        "id": "46zEA-clOqBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from pandas_datareader import data as pdr\n",
        "import fix_yahoo_finance as yf\n",
        "import numpy as np\n",
        "import datetime as dt\n",
        "import matplotlib.mlab as mlab\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm"
      ],
      "metadata": {
        "id": "nD735qL0Nccm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Calculate periodic returns of the stocks in the portfolio"
      ],
      "metadata": {
        "id": "2Vn5V_zxNNTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create our portfolio of equities\n",
        "tickers = ['AAPL','META', 'C', 'DIS']\n",
        "\n",
        "# Set the investment weights (I arbitrarily picked for example)\n",
        "weights = np.array([.25, .3, .15, .3]) \n",
        "\n",
        "# Set an initial investment level (1M USD - for this US-centric example)\n",
        "initial_investment = 1_000_000"
      ],
      "metadata": {
        "id": "g-uxDr3uNCeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert sum(weights) == 1.0"
      ],
      "metadata": {
        "id": "N-m9rcukNw9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download closing prices\n",
        "\n",
        "data = pdr.get_data_yahoo(tickers, start=\"2018-01-01\", end=dt.date.today())['Close']\n",
        "\n",
        "data.tail()"
      ],
      "metadata": {
        "id": "Yg6a74-bNocX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From the closing prices, calculate periodic returns\n",
        "returns = data.pct_change()\n",
        "\n",
        "returns.tail()"
      ],
      "metadata": {
        "id": "Ewn38t3NN4OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Create a covariance matrix based on the returns\n",
        "\n",
        "This will allow us to calculate the standard deviation and mean of returns across the entire portfolio."
      ],
      "metadata": {
        "id": "Jowv-MG3P9ub"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Var-Cov matrix\n",
        "cov_matrix = returns.cov()\n",
        "\n",
        "cov_matrix"
      ],
      "metadata": {
        "id": "1ta3mUFDPWB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Calculate the portfolio mean and standard deviation"
      ],
      "metadata": {
        "id": "DXqjmYZ7QR21"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate mean returns for each stock\n",
        "avg_rets = returns.mean()\n",
        "\n",
        "# Calculate mean returns for portfolio overall, using dot product to \n",
        "# normalize individual means against investment weights\n",
        "\n",
        "# https://en.wikipedia.org/wiki/Dot_product#:~:targetText=In%20mathematics%2C%20the%20dot%20product,and%20returns%20a%20single%20number.\n",
        "\n",
        "port_mean = avg_rets.dot(weights)\n",
        "\n",
        "# Calculate portfolio standard deviation\n",
        "\n",
        "port_stdev = np.sqrt(weights.T.dot(cov_matrix).dot(weights))\n",
        "\n",
        "# Calculate mean of investment\n",
        "\n",
        "mean_investment = (1+port_mean) * initial_investment\n",
        "\n",
        "# Calculate standard deviation of investmnet\n",
        "\n",
        "stdev_investment = initial_investment * port_stdev"
      ],
      "metadata": {
        "id": "CrygMjaWQE70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_rets"
      ],
      "metadata": {
        "id": "qTdz_G_JQfSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port_mean"
      ],
      "metadata": {
        "id": "RXpS3jgXQ4zQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "port_stdev"
      ],
      "metadata": {
        "id": "gpjmZVdWRAoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_investment"
      ],
      "metadata": {
        "id": "w8VEhz0hREHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stdev_investment"
      ],
      "metadata": {
        "id": "W_6bsQ87RGjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we can plug these variables into our percentage point function (PPF) below.\n",
        "\n",
        "### 4) Calculate the inverse of the normal cumulative distribution (PPF) with a specified confidence interval, standard deviation, and mean"
      ],
      "metadata": {
        "id": "OyRDnDqHRQnu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select our confidence interval (I'll choose 95% here)\n",
        "conf_level1 = 0.05\n",
        "\n",
        "# Using SciPy ppf method to generate values for the\n",
        "# inverse cumulative distribution function to a normal distribution\n",
        "\n",
        "# Plugging in the mean, standard deviation of our portfolio\n",
        "# as calculated above\n",
        "\n",
        "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
        "\n",
        "cutoff1 = norm.ppf(conf_level1, mean_investment, stdev_investment)"
      ],
      "metadata": {
        "id": "YzX0c7f8RJsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cutoff1"
      ],
      "metadata": {
        "id": "UHpXhkmDRgfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5) Estimate the value at risk (VaR) for the portfolio by subtracting the initial investment from the calculation in step 4"
      ],
      "metadata": {
        "id": "_6-JcC6ZRnt3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally, we can calculate the VaR at our confidence interval\n",
        "\n",
        "var_1d1 = initial_investment - cutoff1\n",
        "\n",
        "var_1d1"
      ],
      "metadata": {
        "id": "y5qVYzvYRjCD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we are saying with 95% confidence that our portfolio of 1M USD will not exceed losses greater than 28.9k USD over a one day period.\n",
        "\n",
        "### Value at risk over $n$-day time period\n",
        "\n",
        "What if we wanted to calculate this over a larger window of time? Below we can easily do that by just taking our 1 day VaR and multiplying it by the square root of the time period (this is due to the fact that the standard deviation of stock returns tends to increase with the square root of time)."
      ],
      "metadata": {
        "id": "iqnIcFlKYtgb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate n Day VaR\n",
        "\n",
        "var_array = []\n",
        "\n",
        "num_days = int(15)\n",
        "\n",
        "for x in range(1, num_days+1):    \n",
        "    var_array.append(np.round(var_1d1 * np.sqrt(x), 2))\n",
        "    print(str(x) + \" day VaR @ 95% confidence: \" + str(np.round(var_1d1 * np.sqrt(x), 2)))"
      ],
      "metadata": {
        "id": "2KUFfcqQRsui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build plot\n",
        "\n",
        "plt.xlabel(\"Day #\")\n",
        "plt.ylabel(\"Max portfolio loss (USD)\")\n",
        "plt.title(\"Max portfolio loss (VaR) over 15-day period\")\n",
        "plt.plot(range(1, num_days+1), var_array, \"r\")"
      ],
      "metadata": {
        "id": "MpVqlDBiZfpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Extra) Checking distributions of our equities against normal distribution\n",
        "\n",
        "As mentioned in the calculation section, we are assuming that the returns of the equities in our portfolio are normally distributed when calculating VaR. Of course, we can't predict that moving forward, but we can at least check how the historical returns have been distributed to help us assess whether VaR is suitable to use for our portfolio."
      ],
      "metadata": {
        "id": "WMaBHcL_aUE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_return_dist(ticker):\n",
        "  returns[ticker].hist(bins=40, density=True, histtype=\"stepfilled\", alpha=0.5)\n",
        "  x = np.linspace(port_mean - 3*port_stdev, port_mean+3*port_stdev, 100)\n",
        "  plt.plot(x, norm.pdf(x, port_mean, port_stdev), \"r\")\n",
        "  plt.title(ticker + \" returns (binned) vs. normal distribution\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "UR5SCEArZj0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ticker in tickers:\n",
        "  plot_return_dist(ticker)"
      ],
      "metadata": {
        "id": "lIjBQUDZbAcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the above we can see the returns are rarely normally distributed for our chosen stocks since 2018."
      ],
      "metadata": {
        "id": "dy-6UFG0d69s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "t8qpvJuVd_ai"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}